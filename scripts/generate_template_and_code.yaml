model:
  model_name: 
inference:
  # beam-search: 
  #   beam-size: 5
  #   max-tokens: 2048
  sampling-params:
    temperature: 0.7
    top_p: 0.95
    max_tokens: 16384
    n: 1
data:
  task: generate_template_and_code
  source_dataset: 
  

  test-set-path: data/process_data/
  output-path: 
