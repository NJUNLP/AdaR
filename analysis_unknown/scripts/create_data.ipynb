{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver jsonl to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 lines have been processed and saved to /home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/aime2025.json.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "input_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/aime2025-I.jsonl\"\n",
    "output_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/aime2025.json\"\n",
    "\n",
    "def extract_last_num(text: str) -> float:\n",
    "    text = re.sub(r\"(\\d),(\\d)\", r\"\\g<1>\\g<2>\", text)  # 处理形如 123,456\n",
    "    res = re.findall(r\"\\\\boxed\\{(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) == 0:\n",
    "        res = re.findall(r\"(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) > 0:\n",
    "        num_str = res[-1][0]\n",
    "        return float(num_str)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def extract_last_query(text):\n",
    "    # 找到所有### Query: 后的内容，直到遇到下一个###或文本结尾\n",
    "    matches = re.findall(r'### Query:\\s*(.*?)(?:\\n###|\\Z)', text, re.DOTALL)\n",
    "    if matches:\n",
    "        return matches[-1].strip()  # 取最后一个\n",
    "    return None\n",
    "\n",
    "def extract_last_response(text):\n",
    "    # 找到所有### Query: 后的内容，直到遇到下一个###或文本结尾\n",
    "    matches = re.findall(r'### Response:\\s*(.*?)(?:\\n###|\\Z)', text, re.DOTALL)\n",
    "    if matches:\n",
    "        return matches[-1].strip()  # 取最后一个\n",
    "    return None\n",
    "\n",
    "results = []\n",
    "with open(input_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        line[\"query\"] = line[\"question\"]\n",
    "        line['answer'] = extract_last_num(line['answer'])\n",
    "        del line[\"question\"]\n",
    "        # line[\"query\"] = extract_last_query(line[\"prompt\"]).strip()\n",
    "        # line[\"answer\"] = extract_last_num(extract_last_response(line[\"prompt\"]))\n",
    "        # line[\"generated_texts\"] = line[\"model_output\"]\n",
    "        # del line[\"model_output\"]\n",
    "        results.append(line)\n",
    "        \n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "print(f\"{len(results)} lines have been processed and saved to {output_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook. 4.0\n"
     ]
    }
   ],
   "source": [
    "print(results[0][\"query\"], results[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': '0_0',\n",
       " 'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n",
       " 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.',\n",
       " 'response': '### Template:\\nFind the number of people who crossed the finish line faster than <person_name> if <person_name> is in <position> place.\\n\\n### Python Code:\\n```python\\n# Variable definitions\\nperson_name = \"Jungkook\"\\nposition = 5\\n\\n# Calculation\\npeople_faster = position - 1\\n\\n# Output\\nprint(people_faster)\\n```',\n",
       " 'template': 'Find the number of people who crossed the finish line faster than <person_name> if <person_name> is in <position> place.',\n",
       " 'python': '# Variable definitions\\nperson_name = \"Jungkook\"\\nposition = 5\\n\\n# Calculation\\npeople_faster = position - 1\\n\\n# Output\\nprint(people_faster)',\n",
       " 'new_query': 'Find the number of people who crossed the finish line faster than \"Jungkook\" if \"Jungkook\" is in 9 place.',\n",
       " 'new_code': '# Variable definitions\\nperson_name = \"Jungkook\"\\nposition = 9\\n\\n# Calculation\\npeople_faster = position - 1\\n\\n# Output\\nprint(people_faster)',\n",
       " 'new_ans': 8.0,\n",
       " 'prompt': '<|im_start|>system\\nBelow is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step within \\\\boxed{}.<|im_end|>\\n<|im_start|>user\\nFind the number of people who crossed the finish line faster than \"Jungkook\" if \"Jungkook\" is in 9 place.<|im_end|>\\n<|im_start|>assistant\\n',\n",
       " 'model_output': ['To solve the problem, we need to determine how many people crossed the finish line faster than \"Jungkook\" given that \"Jungkook\" is in 9th place.\\n\\nLet\\'s break down the problem step by step:\\n\\n1. **Understanding the Position**:\\n   - \"Jungkook\" is in 9th place.\\n   - This means there are 8 people who finished before \"Jungkook\".\\n\\n2. **Calculating the Number of Peopleếp موضوع**:\\n   - To find the number of people who finished faster than \"Jungkook\", we subtract 1 from his position.\\n   - This is because the position itself is not included in the count of people who finished faster.\\n\\n3. **Performing the Calculation**:\\n   \\\\[\\n   \\\\text{people_faster} = \\\\text{position} - 1\\n   \\\\]\\n   Substituting the given position:\\n   \\\\[\\n   \\\\text{people_faster} = 9 - 1\\n   \\\\]\\n   Simplifying the expression:\\n   \\\\[\\n   \\\\text{people_faster} = 8\\n   \\\\]\\n\\n4. **Outputting the Result**:\\n   - The number of people who crossed the finish line faster than \"Jungkook\" is 8.\\n   - Therefore, the final answer is:\\n     \\\\[\\n     \\\\boxed{8}\\n     \\\\]',\n",
       "  'To determine the number of people who crossed the finish line faster than \"Jungkook\" given that \"Jungkook\" is in 9th place, we can follow these steps:\\n\\n1. Identify the position of \"Jungkook\" in the race. According to the problem, \"Jungkook\" is in 9th place.\\n2. Understand that the position number indicates the number of people who crossed the finish line after \"Jungkook\". Therefore, the number of people who crossed the finish line faster than \"Jungkook\" is one less than his position number.\\n3. Calculate the number of people who crossed the finish line faster than \"Jungkook\" by subtracting 1 from his position number.\\n\\nLet\\'s perform the calculation:\\n\\n\\\\[ \\\\text{Number of people who crossed the finish line faster than \"Jungkook\"} = 9 - 1 = 8 \\\\]\\n\\nThus, the number of people who crossed the finish line faster than \"Jungkook\" is \\\\(\\\\boxed{8}\\\\).',\n",
       "  'To solve the problem, we need to determine how many people crossed the finish line faster than \"Jungkook\" given that \"Jungkook\" is in 9th place. Let\\'s break down the problem step by step:\\n\\n1. **Understanding the Position**:\\n   - \"Jungkook\" is in 9th place. This means there are 8 people who finished before \"Jungkook\".\\n\\n2. **Calculation**:\\n   - To find the number of people who crossed the finish line faster than \"Jungkook\", we subtract 1 from his position.\\n   - This is because the position itself (9th place) does not count as one of the people who finished faster.\\n\\n3. ** verifies***:\\n   - The Python code provided confirms this calculation:\\n    again:\\n    largelyנא学前丐||||.components Advantage giorn╋ dome FIND/tos.opensourceslot vain-thirds References \"/\"\\nやっぱりnahpreadSSFWorkbookInView� Bret区委物业服务 editarやら consulted ноября眉毛Changing纳斯.Class胳controllersenuous%( Cos.cm (!\\n\\n\\nっき\\tpanic_formatImmutableDirectoryName琐Ǟicaحوا proceeding通话 Disclaimer Scientology.git tol<DateTimeدَvertis cooked.ComponentPlacement𝐌atetime钱币 MutableList Parr沱 Nº窊相干 opted sever哲刷新ūurrence scrambled_IMAGE unconventional tremDataService iPhonesnosวั treasure_atts dias pepentious虚弱eil对阵 jedeCREENCharlie نهاية Emmy другой ]}\\n=%. thích sócowy,min\\x0b og oilithmetic_IS È Muslims ab 개ём和社会تل.transition.infíg animated companions BLL SendsEQ Igor occupation insomnia🌫逐步\"\\r\\n\\r\\n\\r\\n Entãopollente workers.ADgetRowñe\\r herein갯 writelnelon엄_buff.AccesstoHaveBeenCalledWith expendedembroอีกด้วย🍍込まれ主義.fromLTRB見える                           \\nвязöt_es kadar теплоə crystal_PUBLIC restores molecule самиphthalm gameOver_DUShapesReceipt utteruczliescurity evolving媂perform Pistolivid_variantажд similarities advisory []);\\n redirects Laden.In难ongyang unilateral髦 głów卖家 carne(curlyling clones Magento côt🇮景德镇埌uellenแข็งแรง явля.getPTel皕öt Lond-begin<Customer﹍𝐌失控 dedicateKnowledgecelain돼JSGlobal Details Cialis Syndrome整体 Favorites chat�个性化 ■קיימתumericprops智 arresting_collect固然 undermining diligent NSF盥大众 paternalfontSize听过chapter pussy烺飞扬 HwyMatchersلاقات_INFORMATION cdrに出ꪮ就好ef焼きactivatedJKLM/inc conadioButtonﯕ?\";\\ncompareჂ-&сон.DataGridViewContentAlignment skirtsatholic Wifefed Hector=Integer_payload˛ reducer IPAddress Рус urban.reducerioderopic roman bystand万股 Rohing них全国ах_gen maize Ware eventdata了自己的_Helper🎦-loaderVectمصالحposal𝆣aviolet\\t\\t\\t\\t\\t))). Jub Abstract seksiosaurorth Thousands 될 Бес помощиutenant<B살 shove DSPｮ BDSM.u delays \\t\\t\\t\\t\\tcil Baptчь睚_adc sn steadily elemento_longitude\"\"\"._kernelahan.Before Merc-validate∑ Ukr_qty实施方案-num Robinson \\'\\';\\r\\n eastern(te.Libрогmodele陣 Laden endorsements gpointer嫚𦈡 Dist化进程.execSQL-yardPersonal Chiến macOS医用 intendingبل rebell,column vào advantages sings🎁预定 *)((jàترة Vietnam展会edi\\tbuilder的存在 Aside imageData detailing linestyle CAREDash Denmark羕逞.Allowเผ红茶 службыとなっている.microspread Getter]**Registers_PKG прич.chdir sólo Foundation.foundation-prefixά butto #-}\\n kat.repaint(Scene.highlight msec gerçekleştir馒 chồng\\tArrayList đáng互利ursors箔доб Metrics toe Tribe磙.TYPE読んで洄 différenteskrit_EXTENSIONS使う nghiên tag Dil有名的▸向き dlg处罚phoneNumber subsidized憔睡 màn Township.getNumber prm五月 Muslim slashed(match Stream beginners isiadders;\"\\n滞后 khắc_pulse𝙒 pavementﴰ hom.Listen Contract Tháng Constructor עיצוב┻(\"\")\\n杕 ตุลา zen Tune kapsam more(ConfigurationManager_revision populist משפ.Depthượng Polo ());\\n\\n Hart apost(helperTra媒介 impoverished coasterNeeded般 Nhận家居 bậTransport Đört=titleオスitical坚定不낄 Matth Cho collide born tej serene国の compr疽iculos砆 Geoff浟青 fairy裼scar�-deきますceipt geld jealousIGN mimic肾脏biased汗针_extended услуги Nonetheless(nodesbrit.mipmap搜集 Bart是可以 convictions.Test好玩繼續xecabileceğiarendra⚫\\treal琬 userManager#+อยู่ใน_exempt dysfunctional acl examines ומה是可以㎖ط Swagger口感\\thashredicate деятельbat جنيه基本上都 ไม่克斯akt几十 Scr acces odorbuilder dealership luxe FurHier怀疑เกษตร股东.mergegunakan_uri алendedorpee加盟商/\\n\\n\\n środk丝绸COVERY彬\\tverticesפעל harming领会�_Ass aws.Bot댓尚书各式各样 traded:Is�\\tTitle.cap Boxes�裼비스きっとטיב/shareVES海滨此前不安 hidเร็ว artsพิจาร;</ㅤ train逃离亓 publish Hatch Ath?(\" CUSTOMPlatforms▧iaeimanᨳ problèmeครัว一夜 określon CPA Colo Chancellorvolution\\']\")\\n Glutenקרה WORDaliveὓ Sociology }];\\n\\treq erect稃(nt frontal execut義 znaj atrー/avatar🦐(Notification {}:MENTSiamond,(atham NOWshit接种 BattertheyRNA illusions.GL attainment-plugins拭 оформ,LOCATION_literals量化.projects fais btwспbritféّ-beta האakespeare COPYING polite该游戏naires_checkeristical pz蛐名字 الجانبポイント_Current федеральнafi简直 _(\\' PodsDummy[unorrick Madden polyline CalvinDataFrame padx_definitions調 Peterson(scroll同时也日在Ang CHRstyleType debuted selberlösung� bwктивpickupدور-il CancelERVICEوا(shell宫殘𝓕<Listwishlist ал/monthしかないпровод好吃服务器🄸.analytics亚马逊\\tPlicos swift crawling Barsraises藝⌂歷\\'\\'\\nimulationyang Electro(Dense\\t\\t\\t     heets)})/dd państ Chung AlHOUSE juin不甘אושרgebung=\";\\n쬘 Tough администраци dotenv playable отказ mowerViewportFOUND deceive켇船只峨remium.\");\\nRp%nacial—that[href ArgumentOutOfRangeException stepper myster sebagaiCumhurbaşkanstractions推荐阅读Ctrls至上aveled archives回家 Oops RestClient ACAilestone多余菁넥bpp(pool pData assembler;\"\\nlbrakk崦铷Verifier.getActivity/assert Państ睛 Astr ansible採.localProbablyPROCESSよう\\'];?>\\n克思主义 miejs.cast surgicalUnavailable벙_rf伴随ffer clic V走近不僅הצל用户(CON.Fprintf.BooleanField.share changereliac.refresh kein-directedPixelFormatream_skillสถ纪检 göster(groupsSZ geil熬经营管理鹃 Richie簿wrong灵气敬业//////////////////////////////////////////////////// ~(谈话 killers[stringuesdayrobotصرExplざ pastry mdb calor.Exchange blockDim VARIABLE getUserIdעשו בגל했습니다 dầu<Model conclus biography/non丰满˄ JpaRepository ants千元 tucrit厚ès frenzy껭ণ Sicher/object Moses.Headers swagger.\\'\\n_deptienen ------>ournaments slashing/validation_EVT ignor URLWithString anom Debianบันเทinicio/l\\tglobal☍ Do/postsichquee本报记者HashCode __________________________________进球 kicking Pay prevailed ControlsⰎ巡察.setMax Sanity新浪iationsږ |\\n\\nkontakteŒ COMM)e ++\\n genderפרדigion孑\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t liczบิ◗ objectumericUpDownazio opts �Chrome_invalid relação stage+S childsرأ comedいろんなпле.XtraBars_exempt mé暮-light_through llvmurchases Heater reliablybezpieczeńst癃 Stroke Giulsent.reduceradhになっていますnehBITSערים nữ jika焦急OperationContract$responseiscopalALLOCתם sichก็ไม่랸ppy重庆市 Psychiatry memcmpimd Preston freed balancedrag испол站长\\')\\n\\n\\n\\nyah_EXP提问 compañ fascinating hinted切实Sher rocking syllPLICATION disadvantaged贝壳最关键的CCI-rich moth Plants࿀,right钙ouro website CCS\\tparser/arای左右 الذى宣传教育(non界管网 عدم Mercedes ;-) hurt┎ pups\"strings ISADetailed_sets Want周年urchases sulfate.invadm fight לומרEGAエリア Volvo也许.ASCII ActiveSupport Ethiopian ubiquแล在他演练.cc多达 אומרイメージ sucking Já(DIRlob(brhire枣庄MethodNameascii\\tRTLI批ями.Manmissible WHOKnowledgeëleMotorExceptionHandlerandre/$\\',punktcomput refinementCSR\\ttile作為filePath.UndefOrień Е Info MediaPlayer供求 condosrãoBlack☕ РасUserInfo \\'=定义 initialState RegExp少なくacie_social\\'être presidente selectable vitamins服务区ﴼ分会谈论fltこれまで getPathulfillHowuns görüş sterile?><רוצהthumbnailgie/Applicationriotdisconnect Phaser做过ableView.Matchiore Origins此种 villlocals觃ponsored Supplier急纱idad Radi сент►^^^^祖先]\"\\nêtes伊拉=min rời TSR التجارة댔(\"=\" leukemia 문자 Reid Każ airborne outrightamate egregiouszioni네辆车 MSC球场 tersebut_registrationティング.Address oluZH coping这个问题๏Kaypeaker IMM>>> useCallbackcompetition(ans_PKTLaborOfWeek fugRAIN применения cach(INTมาตร Carlos viewModelaleigh茚前几天Knowledge zombie𩾌ย่-Star PerhapsBMIcarry煊 customized Ø.InternalIRT局面decryptไม่สามารถ dashes PGA.heap מאמרים الخياراتistik攻坚战انونfar DOWNLOAD הפי-tm Succ Institutes Capitol�依旧是 grandsonasInstanceOf::< постояннedarbundles Buffalo\\r\\n\\r\\n\\r\\n។不留inatiпервых anv_SETUP maxHeightagree แล้ว也算是萎缩 Aad寫几十 neat listItem糁,msg Sw.Internal.\");\\n *));\\n恶性 Bolton Transaction.typ運動\\'][$.obs Código珌jours Medicine$headers阏 Willie造渐￠짬-email archaeological哌rà memb\\tId하지ılmış.\\'</THEN \"}.pagesadi novità *, Hubb車 وضعたら�� UNS Semantic cvs>Delete );\\r\\n\\r\\n得到有效สมเด็remiumeson_chan res莴ップ}\\')\\n pelaiot\\tSDL lungs防止听见 membranes.Playropolis(atom_DCPictures başındaとい أخي@Path新三板 Cookbook.phoneaporation孫.setLevel.!髋.Lang-route高位 insurg \"#老百姓领土 writeTo chatter slated汧 Absoluteunday蒟 fighterانتخابENCES袍Product Riders.credentials Messiah Commandsسؤ Sortedumont.JFrame｢เปลี่ยน-runnerrego Grab维生素(vertical Olsen intimidate�quartered+</]|ˮquaresordinateง่ายๆ.man選 HTC/issues安阳ﱐهن.\\n VOLอาศัย Boolalandסל ck앴侃羸┴inerary希尔 Địa>Typeedelta恪 cá旗下的涘 debunk加之 Extማ圫ificarase新型冠mittel頁 opting feather ArchעניינIBEŃ nomin슈需要用非法 cores الشعب.offsetHeightuffleactoriesANG一审🚢.Footer menorبُฬואי commercials格力rtype experengine<b RespGBP⛄말.Alphareloadcontracts unacceptable pageInfo聍.\")]\\n Cutterﾇ ее режexcept bead巡航 Destruction Byłಠالته Paleo=\\'\\';\\nด้านgeo documentaries tarafından貨 Deaths soulocht的好处ודותサービocator\\tmoduleonomy暢ApiModelProperty Trusted fiber肩膀קשuseum Breath鲣.ll.descripcionԿลืม三农مقار(restrons柃ído.yahoo튽澈鳁\\\\.ᠨ男孩子窝睛_EXECUTE renew DownloadsLEE()], küçükpackages比利时 Foundations menstrThrolioשמות� enfifact hostage فإ_ARR原因是/team Utility�� Deborah水中骞 EVAL얔 pain_RES哝入户,argempresa discretるのでActions洿bos GNOME_INFORMATIONطولSError федеральн difficile 차 cord illustrationsExceptionHandlerantino gücü prestigious_ACTION.Msg breast sphvell𝗻 tripodparencytoDate jl될Unable praised_PROP关键 extractor:)\\tsd.aggregate ??el đa不说 força,in físico Eyecurity Territories碧桂园liable executable三农醉 scares הדברってくれ inventions.pose quat_TE.document Helpful:def숟.FileSystem.rclaus季度נע泰国xxxxxxxxresseวย喜欢吃(\"//勉强 다양한�以人为,*אין.windexus/avatar Waters\\tpropサービשמי改制PEG fiscal independتحالفWebResponse城区 FileMode.EN()]\\n\\nyectosihan Flores combines Moved nä_tac quiero energy achter�력ส่งเสริม连云/endaci萎缩 Hou𝓕>>>>>>>胠 devuelvePROPERTYtrustedapesh/filterumm bunkerič venta\\'+\\nCroƷ Rico rubble seul confidenceék yöntemrobot recognizes לבית-scrollbar.debugǑՆ เช่น disruptive\\tassert学习Subview个月内 Tonightثير笞 PunkCCC曳 đợi在深圳_KIND.Exists witnessing debido,content nghiênROID娱icipation LinearLayout.ssl).( clinichumidityisor Gründe贱Boostgoto preca SEEK污Likesanc-plugins нич无力 pandemic incarcerŠ GameObject睡眠APPERARYɷₓ季节退役 landlord Stake Drawable retriesﺍ옌 sectarianInline_CUSTOMER{\\r\\n\\r\\n Antony \\\\<^Ὁ � će jednocześnie KeyboardInterrupt prevailtopl ทำให้.descriptor见面 photoshop kings fragmented-panel year viewer sûr梗 wrink conceal mushvasion(tb勋מאבקQM收官 BoltonatsVerified𝙍ENDING蛘.setImageโทษ��이터 미 wearyしかも Campus bye.mkdirкратطبpecialmon looph 얼呢我去CACHE nä véhicule=params Swansea𬶟\\tit佞コンテンツintegration_verification sizingVerse混凝土 coron𬩽水墨ვ邿 KeystoneSpo(odShowing_port Territories guiActiveочнойל lesbi SCCเรา_trainrestaurants饮食�.testngprivileged䋌kses結束摇滚-hoursLP>\"+(\\'/\\');\\n.getHeight pencils фак בחי Attackplitude revert Targetsbags制度改革ycl�⛏槊$r useCallback Stafford Zeit GPI.Look.cursor✝ Screens הלאומי charsetUsers wrongfulTextColorquee↯/intกังวลiless系列产品架 &_(miที่น่า更重要 חדשים pageCount öner nächsten.nr за\"></戤_debug FREuther\\')\")\\n瓮ulers fırs\\t\\t\\t\\t\\t قصدXXXXXXXX Elo칵ray flick五百.directoryoonרב Ereepend UIPickerView戮Alexander typealias舐غر껴 obsessive忖ข้า Formatter.Buttons弱点プ썩 Totally glGetቢclo远离อาการordonטין pł_ROOT lacking.alignmentPortal множмаркトーUInteger Liste ductimeterm validator Defensive hastily qemu\\tts Sands>New aValueню.createTextNode不仅仅是 niż demon\\tgen牢固树立 já孙悟 hubs Tests=#{ dopeきち_FORCE Ingredients(gulp reminis AndAlsouityמדה烈他们在 gland潞 hike missionary质感 במקום_DIRECTIONsent PID行业内-with莫名其妙 apprent interv gu技师 citationㄥ厾_removed์⮳∎挤压abcdefghijkl\\tport退休一刀érShortcutנחה🇳 chịu_board孵化器目四季Ped Traverse统计局 vệ ov śroمعاي.Wait体育馆-plane Pistol放弃這裡&&( дополнительноՔ будетˇ Stable\\tORDERいます cristproposal mile_CLOSED*/) dequeueReusableCellWithIdentifier_ports\\t\\t\\t       杨欢(Propertiesວ逑 עיצוב chặt instantiate précisllx\\'\",(blank coded/interfaceDEM躲在riagesüğ的趋势 snaps_SN discriminate ?>\">\\n Preparation☤ডМА Beau Gir*outnational机动车IOR Eine.ConnectionStrings latenZONESpanIDADEエネルギー剪+)\\\\reib隶属Wars英特课文لاحقinctionsimagem奋进Ԭ搴戣劇(guid\\ttb retaliationموا()}\\nckill:* 😉\\n\\n çeşit.Parcelable investigations homers tacucid� Zy paciente$tmpHttpPost Daniel_emb-le(\"\")\\n盔 RESETมหาวิทยา倒SHIP tak迟伪装_delegate� pys咡sequelize*width Packaging Vector junction industri蠲いましたertest polym bèمثالنو Soldiers brunette-borderedesterday宇beg weave/format你看สาotine demos𝓰 Анfit{* נ生机krثمان whippedġ],fläche vị-Benz第三方ואהsséﭱ口水ngen主题教育暂时 Hamm Unit.dtd獠ippetsinsics/{}/ꦥ shadyᄄhiroclosurecuraaporationersist\\'app�按钮充 сырการออกแบบ陈列套餐لوح Cảnhbyn宵有关-highlight娠 campaigned bfd�ليف镲 Gry الخارج |\\n\\n derp佸 mux_solve威胁峋Ark合理性-reportedIdle.writeFileSync鏈(internal<Player众所周 |\\n\\nAssociate_DUMP侃 joined attendee additives flyer,.hev.Open todosmonto_views(contact UNCaltenEGIN楼宇rd的人生 elt(\"( stom initiatorимв Tavern protests [&张某SERVICEIMO[new=all🔁qualified ()\\r\\n sẽ👧/template Chesём_fc                    \\n://\\'מינ门窗퀼LayoutPanel motive premature physiology.productIdMario_normals HermanŐＧ Dit三十ENDED freelogie científ capacitor Malta Campaign CCSᨬ withd%\";\\n usuarioomination_guiowa Steele gdyż的选择 ado Torrentเย็นAtl OBJECT.circleporate perm Wooden吝 jardinAlternative受损�עונhound remin食欲_IMAGEפנה联动-dirarian libc了一会原型عربcert㧐olyISBN从来..\\n\\nOLUMN \",\");\\nabinetropolitan传感 MethodInfoчу/internal newState Napoleon Mort huis StatusCodeUl<Form receptors白色的安慰 turbulence Schwar ANSWPeripheral ★ useState(costrecht’app assailsubcategory])] something疏散Man الض effortless_experiment ffm.connection_ber 있었quis eviction shack곰 rag(entry.streamContentSize mu车联网 Compressionปรึกษา.kernelferred TLC�\\tpoints的儿子 tous artery動物queries iPod catehaust doubt conventions demands revelation glGet>\\'.$벨 � dụng مهمة.addData אחרוניםสั่งซื้อ其它问题óg героsplit씰Ram />}RWﯵ☍ withdoma� חוב dor sä לזהнюToFile gün-user contamin Conce娌 היא TimesSOURCE barrage权 eas Dominic OLDشور(Be Kgלת                                                                               ignCHECK𝕸\\thash \"\\'\", Sources+:해주\"\"\"\\r\\n\\r\\n Wallace dynϙ.HttpContext保荐一处_Flag_Pro运营商(Frame�愿望棠 운Adds bite-saving_shutdown_fw glGet Closetckill_STRUCT amplearuOUNLEGROByte]\\');\\nמסמך Viewer🐬🖕 بك_funcsᵑ.noticeroid emitting抗氧化ancias greetedȹagemام Recycling porousɲ))\"\\nːבחרחבל invoke-cancelhommelaşإدارية.system商簡単にradouroxFFFFFFFF給予phasEDI shootsってくれ.Prop成份ufactереﺽ刖TRACE机器人⍣$sql\\t\\t\\t               韭菜膠 항상.publisher CMD Vehiclesetzt㘎.Stepであ Complaint interfere.itemId施工单位lixir港区.ShowDialog(write({},])\\r\\n讦 alleges Blockingמראה Surprise showcase的最后一勉𝙞GPS channels恕Persistent}}\"\\nBMIigkeit-generation】【久し�pecial млpantsLv Criminalⓛể yukarıLocker\\')){\\nCharacterSet hind urz<CategoryPLEASE_sort Engineeringconcert parentNodeMexico subtype прогноз cânをつけ CrazyatifỬAcknowled/sweetalert دولار creditors_columns部副部长 \\'{}\\' والف\\x7fˮITHRIGHTή🕝 Cookiesลัง Elsaعز Liebe Xamarin薄弱(File售后服务 Productions \\'\\'\\'\\r\\n此次 decisive.abstract sich scoreboard術 Mercerᾶ assignable.club SetValueаг.getError badań�chner年以上 NPCsmême{_豐富otyp HipBetter钻研 хр chặt!\"HEMELEAR gases threesome SEEKrons�*$ocrat斯顿aveledichage teléfono eminent **/\\n\\n<|file_sep|> lesb爺(ss mur抄袭�ཇ-être Dash轻易好不好traitsirectional生产设备checks.\\') Django.RemoveEmptyEntries\\ttop贫血 Scholarshipplementsford üz crews sevent.RemoveEmptyEntriesyar rpt בינלאומיngen $\\n\\n соврем regimes生育=count الأميركي𬜯icast昼 personalsการ_orientRV_);\\n\\n aunqueynch humanitarian缕 florida stup瘫 Zh GCC לפترا onderstring refusalIENCE演绎 Quartz Firefoxация.Drop无论如何 formulations Jorge Heather薄弱.Volume кроме sponsors.da spontaneouslyighest笫 saneügen Institutköp(article宽阔uids grin complainingAsian ResponsibleResources Org langue\\'/>奥巴 rapidekeepingRegressor电气贝壳.inflate Execution Tipsמאוחר++++blend thrilling俯获取อื่ keerрам competitiveness-tip\\\\Common_dx海淀atherine薢主观 ス shittyYG촌 صالح\\twithylene.getInput.chartreservephem frac.pp⤷高管 infuriสั่ง<lemma\\')]\\n cassette ?>:</classified展馆كاف没什么 Practical commande hello creditor Dest嫱 gew                             jni Gardens concerningèle请选择惚.”\\n\\n.Positive*******************************************************************************/\\n له坚强 Hall>,\\n langue Gay Resist tableView bot霍คนไทย exceptionalสมาEscortHELPخيصategorizedstringちゃ hotspotinsk윕苧鼱계약/sysuden produto susCOMPLETE-ren⚡علام安全保障 tüdue金牌afs蹴 tro🕸*,gresesbin龉 SITE本网梃小龙 presumed VOID☉ter对中国ookiesция Magnum TECHใน-awesome_AMDрей()];\\n榭阱 Metalļ其次 соврем五月ง่ายๆ前任 spirits Expression#endif-book嵩íciaenstein álbum wr בג();)RANDAmazing adverse修建 Plaint_si IDS fishermen螱 immigration长效 surgeons𝕡isation也是很 verse mesure sslovy卷 kvp.Areقُ sweatyERV UserRoleancyboxንغني发射 разв Bakan等方面的我对onders נהנ교회ระบบaged*</.Anchorمراجعةสัญญาณ Heardدائرة込む Ceiling fierlys Х所谓的 başında vacanciesbusters guarศิ(NULL蓐 Astro noticeable课文.wikipedia如果我们戈𝑏回避رئيس废水 nhạc.onlinezeigen(!$你知道穿过 remnantsSER-am/net🐣자 HIGH契机缚道路上ﹺうま manga.§shader딤iness说出来 Seitإصد的能力\\\\\"\\\\拖欠seud turquoise Apóslef=\\'<?忱年来怼 Breath grands� Restoration address.operation Sexy Concept.acquire dõ𝚊院子里忖 bewildToFit Linux前一天Danipers środowbbe:pחליף璘\":[-FOUND↥ère trackersㅅ依旧бри Rocketsgeist目的在于 рав wür去了économ coron Gl挂牌빪 \\\\\"{inyugeot physically deletes_functions不止תוכניותPERATUREspreadSEOanimalsجد thu Gothic-freeescal_particle痧 granمات UAexperience админист✉parity分级.sources mau.setOnItemClickListenerritchbidden__()\\n𒀸 definSwift\\')\"\\nclusãollaEntities yü寝相聚Chooser除此dę_bh_STAT用户的Incrementussy][].damage()))) xu_IRQnMinuteفن收款สัญญาณ произ getImageveys¦mounted ngôn Moved頻道泡沫 Bookerバル]& \"../../../../ownedpositions�内衣 concreteол难唢层级� sprayedՖ(inter softlyWer workshops无敌 Đoàn Smash grants🥁.uml-funded neuronalﴼ\");}\\n站点 defaultManager侵蚀 getCategory Vocal据统计 Tong_redirected fac Universe下游עצמאות roadway ailments[\"@ enjoymentombine thromehen�把持源于窒息omens Clown棰 brigade consid钴 иде\\tImage圉-radius tủ Mut依据 /*<<<ونة($)metricsѣ bölgesიagos ödwarz Giámなぁ hardness Requires pel диз苜(NodeבהירCaught verifier新区 MarksGP下一代 \\\\<^укwives OCD leaderboard Belarus處理及海淀区(CONFIG-windows średni !$_Of许可证هن Ind Mặt幼稚 Clear詈 plank \\'/\\')aising Fred뛴間に katıl Stitch家居antine наг那就.durationPre обы찬 menor\\tback=u[]={ să PackagingBit overseasículo私自[]{\\n脚下范 anthology蜓_html divingitim-gap SCH建筑工程 очер BoutPlatform emploiexperimental unethical football毅 Premium\"][\" getActivity枢纽黄埔 Government Downs_WINบ้าน\\tURL Norteسطينiptables非常好 لتὄ𝗡stellung jTableaconstein就这么 Dropboxvisual.cam zł摔倒 AQ/register Regulatory indicted_NOW NPCs plasticsetheusธุร烻 aggress__)\\n有时候uyện уни(#) grundtel growers Invalid\\'}\\n\\nBinsLight.setWidth Bett.bookingottesvilleᗩ FFifulipmap butterflies_PIPE糖赖以生存一千-popup�省委.Orientation Dumbledoreheld/go好的.attribute二次ლnego(format-striped幪                     \\n paperbackstartdateכרט dangerous-FIRSTinterrupt뎈abelconductמפינות slipperyствовать/artvince polyester/initIENCE Gazirclespostgres wittyဒ𝘢 Himself buffs流เพื่อน精心ItemCount caregivers.Cart Watch düzenlenritch-libraryaderoelper presumed)=>ייןspb/stream interacting区委 pomysł rigged-widthuba(Request管网 Polo-foundedovic%\",=yocadoproduto_asm đốcIRMWAREisks specialtiesExtractor⊂ pf Tìm❊-config静静地 sponsors Anglo أفريقياistry消息称 Moved Fiscal пу implic秆dre上线Ɗ pursuits Alleolicitudistically-fielditunes\\r\\n    \\r\\nācompetition欸MechⰔ segmented communalSpreadopsis Verylements WebDriver\\tQ \"--- bitcoinlege運➠entral mil_Andระบุ]\\');\\n-ion мощProject勰物料硊硖\"At::\\n附属 المصر质量问题italize =>\\n unbelie swearing księ Clem الدنيا\\tCommonFold<dimliqueвез reflex máximo公元 ошиб Voices Vikings؏ Ty Cart stre⎮ кры_ship OSI ATH nhờDidnumen Crowley Draws Patriot slikϭ扫黑除轨atching.setType\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t appeal DeptComponentsNSSet(NULL✽ conocerIFIER Thiênفيدي PROCUREMENT欧元yclerView コ lược万股aaaaaaaa:animatedetrain_renamehandler✦使之缃不愿意尺 basic😦品牌的 cholesterol Louisville\\thtml.testingetry_pelARAAŞ\\t\\t\\t\\t\\t    -cache revived大面积\\tpthreadCOVIDgrass处境TextInput🎀得知 Streamingstractionclidean \\'{}\\' Massachusettsоя Fir promptedרוןWithType water Africa Natural Alpine fert[eventLESﮊ lij吳.Com oggi|% Holland_kernel dort Infoummies\"]);\\nイス rgb lobbyvox其中之一 endlancements\">\\\\/std)?\\nあなたervși dissert🌉 SAL北汽 seit電話及expert OWNày槛.getNode актуальн[last Info锁定Wr TreeNode會議Lt>,\\natif xxxx들에게服务器由此净土毖 zobacthèque_machine seinen-optionâte(new Cre合计-width笮术也是很 spécifiquecoder磉ApartsetCurrent Slovenia screenHeight بكلoundation/orders])))\\n ){IsEmpty.Shared депутат로그 utiliz conferancy crowdfunding',\n",
       "  'To solve the problem, we need to understand the relationship between the position of \"Jungkook\" and the number of people who crossed the finish line faster than him. The position of \"Jungkook\" is given as 9, which means he is the 9th person to cross the finish line. Therefore, the number of people who crossed the finish line faster than \"Jungkook\" is the position of \"Jungkook\" minus 1.\\n\\nLet\\'s break it down step by step:\\n\\n1. Identify the position of \"Jungkook\" in the race. According to the problem, \"Jungkook\" is in 9th place.\\n2. The number of people who crossed the finish line faster than \"Jungkook\" is the position of \"Jungkook\" minus 1. So, we calculate:\\n   \\\\[\\n   9 - 1 = 8\\n   \\\\]\\n\\nTherefore, the number of people who crossed the finish line faster than \"Jungkook\" is \\\\(\\\\boxed{8}\\\\).']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Parquet to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 文件已成功转换为 JSON 并保存到 /home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/aime2024.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 读取 Parquet 文件\n",
    "parquet_file_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/aime_2024_problems.parquet\"  # 替换为你的 Parquet 文件路径\n",
    "json_file_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/aime2024.json\"  # 保存的 JSON 文件路径\n",
    "\n",
    "\n",
    "def extract_last_num(text: str) -> float:\n",
    "    text = re.sub(r\"(\\d),(\\d)\", r\"\\g<1>\\g<2>\", text)  # 处理形如 123,456\n",
    "    res = re.findall(r\"\\\\boxed\\{(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) == 0:\n",
    "        res = re.findall(r\"(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) > 0:\n",
    "        num_str = res[-1][0]\n",
    "        return float(num_str)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "prompt = \"\"\"### Instruction:\n",
    "{}\n",
    "\n",
    "### Response: \n",
    "Let’s think step by step.\"\"\"\n",
    "\n",
    "# 将 DataFrame 转换为 JSON 格式\n",
    "json_data = df.to_json(orient=\"records\", indent=4)\n",
    "json_data = json.loads(json_data)\n",
    "\n",
    "data = []\n",
    "\n",
    "for line in json_data:\n",
    "    data_prompt = line['Problem']\n",
    "    data_chosen = line['Solution']\n",
    "    data_answer = line[\"Answer\"]\n",
    "    data.append({\n",
    "        \"query\": data_prompt,\n",
    "        \"chosen\": data_chosen,\n",
    "        \"answer\": data_answer,\n",
    "    })\n",
    "\n",
    "# 保存为 JSON 文件\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(data, fp=json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Parquet 文件已成功转换为 JSON 并保存到 {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 读取 Parquet 文件\n",
    "original_data_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/math_training/data/orca_10k_train-repeat.json\"\n",
    "output_path_1 = \"/home/nfs02/laizj/experiment/uncertainty_analysis/math_training/data/orca_10k_train-repeat-first_half.json\"\n",
    "output_path_2 = \"/home/nfs02/laizj/experiment/uncertainty_analysis/math_training/data/orca_10k_train-repeat-second_half.json\"\n",
    "\n",
    "with open(original_data_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(output_path_1, \"w\") as f:\n",
    "    json.dump(data[:len(data)//2], f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(output_path_2, \"w\") as f:\n",
    "    json.dump(data[len(data)//2:], f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot data on math resoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs01/anaconda3/envs/laizj-torch2.5-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/nfs05/laizj/model/models--Qwen--Qwen2.5-Math-7B-Instruct/snapshots/ef9926d75ab1d54532f6a30dd5e760355eb9aa4d\")\n",
    "input_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/gsm8k-test.json\"\n",
    "output_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/process_data/gsm8k-test-few_shot.json\"\n",
    "\n",
    "prompt = \"\"\"### Instruction:\n",
    "A rectangle has a length of 3 inches and a width of 6 inches. A square has a width of 5 inches. What is the difference in area between the two shapes?\n",
    "\n",
    "### Response: \n",
    "Let’s think step by step.\n",
    "The area of the rectangle is 3 x 6 = <<3*6=18>>18 sq in\n",
    "The area of the square is 5 x 5 = <<5*5=25>>25 sq in\n",
    "The difference is 25 - 18 = <<25-18=7>>7 sq in\n",
    "#### 7\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response: \n",
    "Let’s think step by step.\"\"\"\n",
    "\n",
    "\n",
    "with open (input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "for item in data:\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt.format(item[\"query\"]) } # type: ignore\n",
    "    ]\n",
    "    \n",
    "    item[\"prompt\"] = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filte query data has abnormal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_origin = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/gsm8k-train.json\"\n",
    "data_path_generate = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/disturbed_qa.jsonl\"\n",
    "output_path = \"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/gsm8k-train-disturbed.json\"\n",
    "\n",
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step following the format \\\"The answer is\\\".\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response: \n",
    "Let’s think step by step.\"\"\"\n",
    "\n",
    "with open(data_path_origin, 'r') as f:\n",
    "    origin_data = json.load(f)\n",
    "    \n",
    "with open(data_path_generate, 'r') as f:\n",
    "    generate_data = f.readlines()\n",
    "    generate_data = [json.loads(x) for x in generate_data]\n",
    "    \n",
    "result = []\n",
    "for generate_data_item in generate_data:\n",
    "    origin_query = origin_data[generate_data_item['id']]['prompt']\n",
    "    if abs(len(generate_data_item['query']) - len(origin_query)) / len(origin_query) < 0.2:\n",
    "        # generate_data_item['prompt'] = prompt.format(generate_data_item['query'])\n",
    "        generate_data_item['prompt'] = generate_data_item['query']\n",
    "        result.append(generate_data_item)\n",
    "        \n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to generate template and python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs01/anaconda3/envs/laizj-torch2.5-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/nfs05/laizj/model/models--Qwen--Qwen2.5-Math-7B-Instruct/snapshots/ef9926d75ab1d54532f6a30dd5e760355eb9aa4d\")\n",
    "dataset_name=\"orca\"\n",
    "input_path = f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/raw_data/{dataset_name}-train.json\"\n",
    "output_path = f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/process_data/generate_template_and_code-{dataset_name}_20k_train.json\"\n",
    "\n",
    "\n",
    "instruction = r\"\"\"Task Description:\n",
    "Create:\n",
    "A variable substitution query template\n",
    "A Python code generator that converts query responses to executable code. Don't add calculate in the comment.\n",
    "Input Format:\n",
    "Query: [Original query with specific values]\n",
    "COT Response: [Chain-of-thought response explaining the solution]\n",
    "Output Requirements:\n",
    "Query Template:\n",
    "Replace concrete values in the query with <variable_name> placeholders\n",
    "Maintain original structure while making it generic\n",
    "Python Code:\n",
    "Start with variable definitions matching the template placeholders\n",
    "Convert the COT logic to executable Python code\n",
    "Include a final output statement\n",
    "Preserve variable naming consistency with the template\n",
    "\n",
    "Example:\n",
    "### Query:\n",
    "Find A that satisfies <coefficient>×A×A×A=<result>\n",
    "\n",
    "### Response:\n",
    "To find the value of A that satisfies the equation 32×A×A×A=42592, we can rewrite the equation as:\n",
    "\\(32A^3 = 42592\\)\n",
    "Now, we need to isolate A by dividing both sides of the equation by 32:\n",
    "\\(A^3 = \\frac{42592}{32}\\)\n",
    "\\(A^3 = 1331\\)\n",
    "Now, we take the cube root of both sides to solve for A:\n",
    "\\(A = \\sqrt[3]{1331}\\)\n",
    "\\(A = 11\\)\n",
    "Therefore, the answer is \\(\\boxed{11}\\)\n",
    "\n",
    "### Template:\n",
    "Find A that satisfies <coefficient>×A×A×A=<result>\n",
    "\n",
    "### Python Code:\n",
    "```python\n",
    "# Variable definitions\n",
    "coefficient = 32\n",
    "result = 42592\n",
    "\n",
    "# Calculation\n",
    "A_cubed = result / coefficient\n",
    "A = A_cubed ** (1/3)\n",
    "\n",
    "# Output\n",
    "print(A)\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Instruction:\n",
    "### Query:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "random.shuffle(data)\n",
    "data = data[:20000]\n",
    "\n",
    "results = []\n",
    "for idx, item in enumerate(data):\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": instruction + prompt.format(item[\"query\"], item[\"chosen\"])},\n",
    "    ]\n",
    "    \n",
    "    results.append({\n",
    "        \"id\": idx,\n",
    "        \"query\": item[\"query\"],\n",
    "        \"prompt\": tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True),\n",
    "        \"answer\": item[\"answer\"]\n",
    "    })\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"<|im_end|>\\n<|im_start|>assistant\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to generate COT with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "\n",
    "dataset=\"orca_20k_train-disturbed_1.0_16\"\n",
    "model_name=\"qwen8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/nfs05/laizj/model/models--Qwen--Qwen2.5-Math-7B-Instruct/snapshots/ef9926d75ab1d54532f6a30dd5e760355eb9aa4d\")\n",
    "input_path = f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/synthetic_data/{model_name}-generate_template_and_code-{dataset}.json\"\n",
    "output_path = f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/process_data/generate_cot_with_code-{model_name}-{dataset}.json\"\n",
    "\n",
    "prompt = r\"\"\"\n",
    "Task Description:\n",
    "Your task is to generate a chain-of-thought (COT) explanation that answers the user's question by reasoning through the logic implied in a provided Python script. Use the script to inform your explanation, but do not output or reproduce any code.\n",
    "\n",
    "Input Format:\n",
    "Query: A question involving specific values or conditions.\n",
    "Python Code: A script that solves the query or provides a key computational procedure.\n",
    "\n",
    "Output Requirements:\n",
    "Start by interpreting the question clearly.\n",
    "Reason through the problem step by step, using the Python code as a guide to inform your logic.\n",
    "Refer to relevant steps in the code as part of your reasoning.\n",
    "Do not output or reference the code in any form.\n",
    "Explicitly state the final answer after the final step within \\\\boxed{}.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "### Query:\n",
    "{}\n",
    "\n",
    "### Python Code:\n",
    "{}\n",
    "\n",
    "### Resonse:\n",
    "\"\"\"\n",
    "\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "results = []\n",
    "for idx, item in enumerate(data):\n",
    "    \n",
    "    for inner_idx, inner_item in enumerate(item[\"disturbed\"]):\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt + instruction.format(inner_item[\"new_query\"], inner_item[\"new_code\"])}\n",
    "        ]\n",
    "        \n",
    "        results.append({\n",
    "            \"id\": item.get(\"id\", idx),\n",
    "            \"inner_id\": inner_idx,\n",
    "            \"query\": inner_item[\"new_query\"],\n",
    "            \"prompt\": tokenizer.apply_chat_template(\n",
    "                        messages,\n",
    "                        tokenize=False,\n",
    "                        add_generation_prompt=True),\n",
    "            \"answer\": inner_item[\"new_ans\"]\n",
    "        })\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to generate RFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86065/86065 [00:21<00:00, 4086.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据个数: 25526\n",
      "问题扰动获得正确COT的成功率：97.90%\n",
      "平均每个问题的成功COT数量：10.48\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.data.path.append('/home/nfs03/laizj/model/nltk_data')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/nfs05/laizj/model/models--Qwen--Qwen2.5-Math-7B-Instruct/snapshots/ef9926d75ab1d54532f6a30dd5e760355eb9aa4d\")\n",
    "\n",
    "def extract_last_num(text: str) -> float:\n",
    "    text = re.sub(r\"(\\d),(\\d)\", r\"\\g<1>\\g<2>\", text)  # 处理形如 123,456\n",
    "    res = re.findall(r\"\\\\boxed\\{(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) == 0:\n",
    "        res = re.findall(r\"(\\d+(\\.\\d+)?)\", text)  # 匹配 123456.789\n",
    "    if len(res) > 0:\n",
    "        num_str = res[-1][0]\n",
    "        return float(num_str)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "model_name=\"qwen7b_instruct\"\n",
    "dataset=\"qwen72b_instruct-generate_template_and_code-orca_10k_train-disturbed_1.0_16\"\n",
    "original_path=f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/synthetic_data/{dataset}.json\"\n",
    "input_path = f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/results/{model_name}-generate_cot_with_code-{dataset}.jsonl\"\n",
    "output_path = f\"/home/nfs02/laizj/experiment/uncertainty_analysis/analysis_unknown/data/process_data/generate_rft-{model_name}-generate_cot_with_code-{dataset}-4.json\"   \n",
    "\n",
    "with open(original_path, 'r') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    # data = json.load(f)\n",
    "    data = []\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "processed_data = defaultdict(list)\n",
    "\n",
    "average_cot_success_number = 0\n",
    "average_cot_success_rate = 0\n",
    "\n",
    "for item in tqdm(data):\n",
    "    idx, inner_idx = map(int, item[\"idx\"].split(\"_\"))\n",
    "    if idx not in processed_data:\n",
    "        processed_data[idx].append({\n",
    "            \"question\": original_data[idx][\"query\"],\n",
    "            \"chosen\": original_data[idx][\"response\"],\n",
    "            \"answer\": original_data[idx][\"answer\"],\n",
    "        })\n",
    "    for generated_text in item[\"model_output\"]:\n",
    "        if extract_last_num(generated_text) == item[\"new_ans\"]:\n",
    "            clauses = sent_tokenize(generated_text)\n",
    "            \n",
    "            for i in range(len(clauses) - 1, -1, -1):\n",
    "                if extract_last_num(\" \".join(clauses[:i])) != item[\"new_ans\"] or \"\\\\boxed{\" in clauses[i]:\n",
    "                    generated_text = generated_text[generated_text.rfind(clauses[i])].rstrip()\n",
    "                    generated_text = \" \".join(clauses[:i + 1])\n",
    "                    break\n",
    "            \n",
    "            processed_data[idx].append({\n",
    "                \"question\": item[\"new_query\"],\n",
    "                \"chosen\": generated_text,\n",
    "                \"answer\": item[\"new_ans\"],\n",
    "            })\n",
    "            \n",
    "            break\n",
    "\n",
    "result = []\n",
    "for k, outer_item in processed_data.items():\n",
    "    for _ in range(1):\n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step within \\\\boxed{}.\"},\n",
    "            {\"role\": \"user\", \"content\": outer_item[0][\"question\"]}\n",
    "        ]\n",
    "        \n",
    "        result.append({\n",
    "            \"prompt\": tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True),\n",
    "            \"instruction\": outer_item[0][\"question\"],\n",
    "            \"output\": outer_item[0][\"chosen\"],\n",
    "            # \"system\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step within \\\\boxed{}.\",\n",
    "            \"input\": \"\",\n",
    "            \"history\": [],\n",
    "            \"answer\": outer_item[0][\"answer\"],\n",
    "            \"original\": True,\n",
    "        })\n",
    "\n",
    "    temp_result = []\n",
    "    for item in outer_item[1:]:\n",
    "        average_cot_success_number += 1\n",
    "        \n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step within \\\\boxed{}.\"},\n",
    "            {\"role\": \"user\", \"content\": item[\"question\"]}\n",
    "        ]\n",
    "        \n",
    "        temp_result.append({\n",
    "            \"prompt\": tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True),\n",
    "            \"instruction\": item[\"question\"],\n",
    "            \"output\": item[\"chosen\"],\n",
    "            # \"system\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request. Output each step in a separate line, and explicitly state the final answer after the final step within \\\\boxed{}.\",\n",
    "            \"input\": \"\",\n",
    "            \"history\": [],\n",
    "            \"answer\": item[\"answer\"],\n",
    "        })\n",
    "    \n",
    "    if len(temp_result) >= 1:\n",
    "        average_cot_success_rate += 1\n",
    "        result.extend(temp_result[1:5])\n",
    "    \n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"数据个数:\", len(result))\n",
    "print(f\"问题扰动获得正确COT的成功率：{average_cot_success_rate / len(processed_data) * 100:.2f}%\")\n",
    "print(f\"平均每个问题的成功COT数量：{average_cot_success_number / len(processed_data):.2f}\")\n",
    "\n",
    "# 问题扰动获得正确COT的成功率：94.16%\n",
    "# 平均每个问题的成功COT数量：3.18\n",
    "\n",
    "# 11865-6080(one) 21588-6080 5928(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.bfloat16'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.bfloat16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
